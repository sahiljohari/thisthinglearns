{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Reinforcement Learning on Snake\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: [Sahil Johari](http://www.sahiljohari.com/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Need to write this_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TO-DO:\n",
    "* Configurable fps for output\n",
    "* Code commenting and clean-up\n",
    "* Display score for each game -- **Done**\n",
    "* Add graphs to visualize performance of model\n",
    "* Results evaluation\n",
    "* Parallelize model for GPU\n",
    "* Add stopping condition while testing -- **Done**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from collections import namedtuple\n",
    "import itertools as it\n",
    "import os\n",
    "from random import sample as rsample\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Convolution2D, Conv2D\n",
    "from keras.layers.core import Dense, Flatten\n",
    "from keras.optimizers import SGD, RMSprop\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import display, clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Snake(object):\n",
    "    def __init__(self, rewards, grid_size):\n",
    "        self.grid_size = grid_size\n",
    "        self.snake_length = 3\n",
    "        self.Fruit = namedtuple('Fruit', ['x', 'y'])\n",
    "        self.life_reward = rewards[0]\n",
    "        self.death_reward = rewards[1]\n",
    "        self.reset()\n",
    "        \n",
    "    def reset(self):\n",
    "        self.actions = [(-1, 0)] * self.snake_length  # An action for each snake segment\n",
    "        self.head_x = self.grid_size // 2 - self.snake_length // 2\n",
    "        self.snake = [(x, self.grid_size // 2) for x in range(self.head_x, self.head_x + self.snake_length)]\n",
    "        self.grow = -1  # Don't start growing snake yet\n",
    "        self.fruit = self.Fruit(-1, -1)\n",
    "        \n",
    "    def play(self):\n",
    "        self.reset()\n",
    "        while True:\n",
    "            # Draw borders\n",
    "            screen = np.zeros((self.grid_size, self.grid_size))\n",
    "            screen[[0, -1]] = 1\n",
    "            screen[:, [0, -1]] = 1\n",
    "            sum_of_borders = screen.sum()\n",
    "\n",
    "            # Draw snake\n",
    "            for segm in self.snake:\n",
    "                x, y = segm\n",
    "                screen[y, x] = 1\n",
    "\n",
    "            # Snake hit into wall or ate itself\n",
    "            end_of_game = len(self.snake) > len(set(self.snake)) or screen.sum() < sum_of_borders + len(self.snake)\n",
    "            reward = self.death_reward * end_of_game\n",
    "\n",
    "            # Draw fruit\n",
    "            if screen[self.fruit.y, self.fruit.x] > .5:\n",
    "                self.grow += 1\n",
    "                reward = len(self.snake) * self.life_reward\n",
    "                while True:\n",
    "                    self.fruit = self.Fruit(*np.random.randint(1, self.grid_size - 1, 2))\n",
    "                    if screen[self.fruit.y, self.fruit.x] < 1:\n",
    "                        break\n",
    "\n",
    "            screen[self.fruit.y, self.fruit.x] = .5\n",
    "\n",
    "            action = yield screen, reward, len(self.snake)-self.snake_length\n",
    "\n",
    "            step_size = sum([abs(act) for act in action])\n",
    "            if not step_size:\n",
    "                action = self.actions[0]  # Repeat last action\n",
    "            elif step_size > 1:\n",
    "                raise ValueError('Cannot move more than 1 unit at a time')\n",
    "\n",
    "            self.actions.insert(0, action)\n",
    "            self.actions.pop()\n",
    "\n",
    "            # For as long as the snake needs to grow,\n",
    "            # copy last segment, and add (0, 0) action\n",
    "            if self.grow > 0:\n",
    "                self.snake.append(self.snake[-1])\n",
    "                self.actions.append((0, 0))\n",
    "                self.grow -= 1\n",
    "\n",
    "            # Update snake segments\n",
    "            for ix, act in enumerate(self.actions):\n",
    "                x, y = self.snake[ix]\n",
    "                delta_x, delta_y = act\n",
    "                self.snake[ix] = x + delta_x, y + delta_y\n",
    "\n",
    "            if end_of_game:\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling an Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent(object):\n",
    "    def __init__(self, \n",
    "                 all_possible_actions,\n",
    "                 gamma=0.9, \n",
    "                 nb_epochs=1000,\n",
    "                 batch_size=32,\n",
    "                 epsilon=1,\n",
    "                 nb_frames = 4,\n",
    "                 grid_size=10,\n",
    "                 rewards=[1, -1],\n",
    "                load_path=''):\n",
    "        \n",
    "        self.gamma = gamma\n",
    "        self.nb_epochs = nb_epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.epsilon = epsilon\n",
    "        self.action_set = all_possible_actions\n",
    "        self.nb_actions = len(self.action_set)\n",
    "        self.rewards = rewards\n",
    "        self.nb_frames = nb_frames\n",
    "        \n",
    "        self.grid_size = grid_size\n",
    "\n",
    "        self.model = self.build_model(load_path)\n",
    "        \n",
    "        self.env = Snake(self.rewards, self.grid_size)\n",
    "        \n",
    "    def build_model(self, load_path):\n",
    "        num_filters = [16, 32]\n",
    "        \n",
    "        model = Sequential()\n",
    "        model.add(BatchNormalization(axis=1, input_shape=(self.nb_frames, self.grid_size, self.grid_size)))\n",
    "        for filters in num_filters:\n",
    "            model.add(Conv2D(filters=filters, \n",
    "                             input_shape = (self.nb_frames, self.grid_size, self.grid_size), \n",
    "                             kernel_size=(3,3), \n",
    "                             padding='same', \n",
    "                             activation='relu'))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(256, activation='relu'))\n",
    "        model.add(Dense(self.nb_actions))\n",
    "        if load_path!='':\n",
    "            model.load_weights(load_path)\n",
    "        model.compile(RMSprop(), 'MSE')\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def experience_replay(self, batch_size):\n",
    "        \"\"\"\n",
    "        Coroutine of experience replay.\n",
    "\n",
    "        Provide a new experience by calling send, which in turn yields \n",
    "        a random batch of previous replay experiences.\n",
    "        \"\"\"\n",
    "        memory = []\n",
    "        while True:\n",
    "            experience = yield rsample(memory, batch_size) if batch_size <= len(memory) else None\n",
    "            memory.append(experience)\n",
    "            \n",
    "    def train(self):\n",
    "        exp_replay = self.experience_replay(self.batch_size)\n",
    "        # Start experience replay coroutine\n",
    "        next(exp_replay)\n",
    "\n",
    "        for i in range(self.nb_epochs):\n",
    "            g = self.env.play()\n",
    "            screen, _, _ = next(g)\n",
    "            S = np.asarray([screen] * self.nb_frames)\n",
    "            try:\n",
    "                # Decrease epsilon over the first half of training\n",
    "                if self.epsilon > .1:\n",
    "                    self.epsilon -= .9 / (self.nb_epochs / 2)\n",
    "\n",
    "                loss = 0.\n",
    "                while True:\n",
    "                    ix = np.random.randint(self.nb_actions)\n",
    "                    if np.random.random() > self.epsilon:\n",
    "                        ix = np.argmax(self.model.predict(S[np.newaxis]), axis=-1)[0]\n",
    "\n",
    "                    action = self.action_set[ix]\n",
    "                    screen, reward, _ = g.send(action)\n",
    "                    S_prime = np.zeros_like(S) \n",
    "                    S_prime[1:] = S[:-1]\n",
    "                    S_prime[0] = screen\n",
    "                    experience = (S, action, reward, S_prime)\n",
    "                    S = S_prime\n",
    "\n",
    "                    batch = exp_replay.send(experience)\n",
    "                    if batch:\n",
    "                        inputs = []\n",
    "                        targets = []\n",
    "                        for s, a, r, s_prime in batch:\n",
    "                            # The targets of unchosen actions are set to the q-values of the model,\n",
    "                            # so that the corresponding errors are 0. The targets of chosen actions\n",
    "                            # are set to either the rewards, in case a terminal state has been reached, \n",
    "                            # or future discounted q-values, in case episodes are still running.\n",
    "                            t = self.model.predict(s[np.newaxis]).flatten()\n",
    "                            ix = self.action_set.index(a)\n",
    "                            if r < 0:\n",
    "                                t[ix] = r\n",
    "                            else:\n",
    "                                t[ix] = r + self.gamma * self.model.predict(s_prime[np.newaxis]).max(axis=-1)\n",
    "                            targets.append(t)\n",
    "                            inputs.append(s)\n",
    "\n",
    "                        loss += self.model.train_on_batch(np.array(inputs), np.array(targets))\n",
    "                        # print(loss)\n",
    "\n",
    "            except StopIteration:\n",
    "               pass\n",
    "\n",
    "            if (i + 1) % 100 == 0:\n",
    "                print ('Epoch %6i/%i, loss: %.6f, epsilon: %.3f' % (i + 1, self.nb_epochs, loss, self.epsilon))\n",
    "                \n",
    "            if (i+1) % 500 == 0:\n",
    "                self.model.save_weights('snake_weights.h5', overwrite=True)\n",
    "        print('Training complete..')\n",
    "    \n",
    "    def render(self):\n",
    "        if 'images' not in os.listdir('.'):\n",
    "            os.mkdir('images')\n",
    "        frame_cnt = it.count()\n",
    "        while True:\n",
    "            screen = (yield)\n",
    "            clear_output(wait=True)\n",
    "            plt.imshow(screen, interpolation='none', cmap='gray')\n",
    "            display(plt.gcf())\n",
    "    #         plt.savefig('images/%04i.png' % (next(frame_cnt), ))\n",
    "    \n",
    "    def test(self, nb_episodes=10):\n",
    "        img_saver = self.render()\n",
    "        next(img_saver)\n",
    "        max_episode_length = 100\n",
    "#         test_results = []\n",
    "        game_cnt = it.count(1)\n",
    "        for _ in range(nb_episodes):\n",
    "            g = self.env.play()\n",
    "            screen, _, init_score = next(g)\n",
    "            img_saver.send(screen)\n",
    "            frame_cnt = it.count()\n",
    "            try:\n",
    "                S = np.asarray([screen] * self.nb_frames)\n",
    "                while True:\n",
    "                    if next(frame_cnt) > max_episode_length and (score-init_score in [0,1,2,3]):\n",
    "                        raise StopIteration\n",
    "                    next(frame_cnt)\n",
    "                    ix = np.argmax(self.model.predict(S[np.newaxis]), axis=-1)[0]\n",
    "                    screen, _, score = g.send(self.action_set[ix])\n",
    "                    S[1:] = S[:-1]\n",
    "                    S[0] = screen\n",
    "                    img_saver.send(screen)\n",
    "            \n",
    "            except StopIteration:\n",
    "                display(plt.title('Played %3i frames for game %3i with score: %d' % (next(frame_cnt), next(game_cnt), score)))\n",
    "        \n",
    "#             test_results.append[score]\n",
    "        img_saver.close()\n",
    "        \n",
    "#         plt.bar(range(len(test_results)),score)\n",
    "#         plt.ylim([min(scores)-0.01,max(scores)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = [\n",
    "    ((0, 0), (-1, 0), (1, 0), (0, -1), (0, 1)), #action_set\n",
    "    0.85, #gamma\n",
    "    1000, #epochs\n",
    "    64, #batch_size\n",
    "    1, #epsilon\n",
    "    4, #number of frames\n",
    "    10, #grid size\n",
    "    [1, -1], #reward set\n",
    "    'snake_weights.h5' #load weights path\n",
    "#     ''\n",
    "    ]\n",
    "\n",
    "agent = Agent(*args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   1000/1000, loss: 164.784248, epsilon: 0.100\n",
      "Training complete..\n"
     ]
    }
   ],
   "source": [
    "agent.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Played  48 frames for game   2 with score: 0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "agent.test(nb_episodes=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "* [Basic Reinforcement Learning by VÃ­ctor Mayoral Vilches](https://github.com/vmayoral/basic_reinforcement_learning/blob/master/tutorial6/examples/Snake/snake.py)\n",
    "\n",
    "* [Interactive Python Notebook for RL in Catch](https://gist.github.com/cadurosar/bd54c723c1d6335a43c8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
