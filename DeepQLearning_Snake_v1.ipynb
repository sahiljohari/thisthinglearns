{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Reinforcement Learning on Snake\n",
    "<hr>\n",
    "\n",
    "Author: [Sahil Johari](http://www.sahiljohari.com/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TO-DO:\n",
    "* Add references\n",
    "* Add comments and clean-up code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep reinforcement learning (DRL) is poised to revolutionize the field of artificial intelligence (AI) and represents a step toward building autonomous systems with a higher level of understanding of the visual world. Currently, deep learning is enabling reinforcement learning (RL) to scale to problems that were previously intractable, such as learning to play video games directly from pixels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reinforcement learning**, explained simply, is a computational approach where an agent interacts with an environment by taking actions in which it tries to maximize an accumulated reward. Here is a simple graph, which I will be referring to often:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A reinforcement learning problem is characterized by the following components:\n",
    "\n",
    "* A state space, which is the set of all possible states,\n",
    "* An action space, which is the set of all possible actions,\n",
    "* A cost function, which measures how bad a state is,\n",
    "* A time horizon, which is the number of time steps,\n",
    "* An initial state probability distribution, which specifies how frequently different states occur at the beginning before any action is taken, and\n",
    "* A state transition probability distribution, which specifies how the state changes (probabilistically) after a particular action is taken."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Q_learning.PNG\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An agent in a current state (St) takes an action (At) to which the environment reacts and responds, returning a new state(St+1) and reward (Rt+1) to the agent. Given the updated state and reward, the agent chooses the next action, and the loop repeats until an environment is solved or terminated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, I will be implementing a **deep Q-network (DQN)** to play a simple game of *Snake*. The goal is to maximize the score of game in a 10x10 space and modify the DQN to stretch out the performance as much as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-learning and Deep Q-Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two main approaches to solving RL problems:\n",
    "* Methods based on value functions\n",
    "* Methods based on policy search\n",
    "\n",
    "There is also a hybrid actor-critic approach that employs both value functions and policy search. As far as the scope of this project is concerned, I am going to use the _value functions_ approach to play the Snake game.\n",
    "\n",
    "In Q-learning, which is a value functions approach, we use a *Q-table* that maps environment states with actions taken on them. For each (state, action) pair, there is a reward that the agent achieves. The idea is to pick a value that maximizes the cumulative reward by the end of an episode. To do this, we use an equation called the *Bellman equation*, which is shown below:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Bellman_equation.PNG\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The agent starts by choosing an action with the highest Q value for the current state using argmax. Argmax will return the index/action with the highest value for that state. Initially, our Q table will be all zeros. But, after every step, the Q values for state-action pairs will be updated.\n",
    "\n",
    "- The agent then takes action and we store the future state as state2 (St+1). This will allow the agent to compare the previous state to the new state.\n",
    "\n",
    "- We update the state-action pair (St , At) for Q using the reward, and the max Q value for state2 (St+1). This update is done using the action value formula (based upon the Bellman equation) and allows state-action pairs to be updated in a recursive fashion (based on future values). Note that we still do not have a discount factor included in this model.\n",
    "\n",
    "This is **Q-learning in a nutshell**. To know more about it, refer the citations at the bottom of this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **Deep Q-network**, simply put, is an extension of Q-learning in which the Q-values are approximated using a *deep neural network*. This technique shows a great improvement in the outcome of a reinforcement problem, however, it is not always required. When you have a complex environment space with various factors to consider for an agent to solve it, a DQN would prove to be quite useful.\n",
    "\n",
    "Now that a basic understanding of the concepts has been established, I would start building the game environment followed by the agent to solve it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from collections import namedtuple\n",
    "import itertools as it\n",
    "import os\n",
    "from random import sample as rsample\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.layers.core import Dense, Flatten, Dropout\n",
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import display, clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the game"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to create an environment for our agent to operate on. This has been implemented in a simple way using Python coroutines and will be rendered (or displayed) using _Pyplot_ (from Matplotlib). It can also be implemented in a way similar to [OpenAI Gym](https://gym.openai.com/) environments, but I specifically want my own environment to control all the aspects of its execution behavior.\n",
    "\n",
    "If you are using this notebook, feel free to tinker with the code and possibly improve it. You can find the original source of this code in the **References** section [here](#references)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Snake(object):\n",
    "    def __init__(self, rewards, grid_size):\n",
    "        self.grid_size = grid_size\n",
    "        self.snake_length = 3\n",
    "        self.Fruit = namedtuple('Fruit', ['x', 'y'])\n",
    "        self.life_reward = rewards[0]\n",
    "        self.alive_reward = rewards[1]\n",
    "        self.death_reward = rewards[2]\n",
    "        self.reset()\n",
    "        \n",
    "    def reset(self):\n",
    "        self.actions = [(-1, 0)] * self.snake_length  # An action for each snake segment\n",
    "        self.head_x = self.grid_size // 2 - self.snake_length // 2\n",
    "        self.snake = [(x, self.grid_size // 2) for x in range(self.head_x, self.head_x + self.snake_length)]\n",
    "        self.grow = -1  # Don't start growing snake yet\n",
    "        self.fruit = self.Fruit(-1, -1)\n",
    "        \n",
    "    def play(self):\n",
    "        self.reset()\n",
    "        while True:\n",
    "            # Draw borders\n",
    "            screen = np.zeros((self.grid_size, self.grid_size))\n",
    "            screen[[0, -1]] = 1\n",
    "            screen[:, [0, -1]] = 1\n",
    "            sum_of_borders = screen.sum()\n",
    "\n",
    "            # Draw snake\n",
    "            for segm in self.snake:\n",
    "                x, y = segm\n",
    "                screen[y, x] = 1\n",
    "\n",
    "            # Snake hit into wall or ate itself\n",
    "            end_of_game = len(self.snake) > len(set(self.snake)) or screen.sum() < sum_of_borders + len(self.snake)\n",
    "            reward = self.death_reward * end_of_game if end_of_game else self.alive_reward\n",
    "\n",
    "            # Draw fruit\n",
    "            if screen[self.fruit.y, self.fruit.x] > .5:\n",
    "                self.grow += 1\n",
    "                reward = len(self.snake) * self.life_reward\n",
    "                while True:\n",
    "                    self.fruit = self.Fruit(*np.random.randint(1, self.grid_size - 1, 2))\n",
    "                    if screen[self.fruit.y, self.fruit.x] < 1:\n",
    "                        break\n",
    "\n",
    "            screen[self.fruit.y, self.fruit.x] = .5\n",
    "\n",
    "            action = yield screen, reward, len(self.snake)-self.snake_length\n",
    "\n",
    "            step_size = sum([abs(act) for act in action])\n",
    "            if not step_size:\n",
    "                action = self.actions[0]  # Repeat last action\n",
    "            elif step_size > 1:\n",
    "                raise ValueError('Cannot move more than 1 unit at a time')\n",
    "\n",
    "            self.actions.insert(0, action)\n",
    "            self.actions.pop()\n",
    "\n",
    "            # For as long as the snake needs to grow,\n",
    "            # copy last segment, and add (0, 0) action\n",
    "            if self.grow > 0:\n",
    "                self.snake.append(self.snake[-1])\n",
    "                self.actions.append((0, 0))\n",
    "                self.grow -= 1\n",
    "\n",
    "            # Update snake segments\n",
    "            for ix, act in enumerate(self.actions):\n",
    "                x, y = self.snake[ix]\n",
    "                delta_x, delta_y = act\n",
    "                self.snake[ix] = x + delta_x, y + delta_y\n",
    "\n",
    "            if end_of_game:\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling an Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the environment set-up, it is time to create our agent which will play the game. Let us understand the structure and working of this agent.\n",
    "\n",
    "**Agent Parameters:**\n",
    "Our agents takes a set of input parameters inorder to build itself on top of them. Here is a list:\n",
    "* **all_possible_actions**: This is the set of actions which the agent can perform on the snake. The values are (0, 0) No action, (0, 1) Move up, (1, 0) Move right, (0, -1) Move down, (-1, 0) Move left.\n",
    "\n",
    "* **gamma**: This is the discount factor which we previously saw in the Q-learning section.\n",
    "\n",
    "* **nb_epochs**: As the agent is using a deep Q-network, it needs a certain number of training iterations to learn how to play, which is specified using this parameter.\n",
    "\n",
    "* **batch_size**: These are the number of experiences that will be used to train the agent at a time.\n",
    "\n",
    "* **epsilon**: Epsilon governs the randomness in the actions taken by the agent on the environment. As our agent proceeds with the game and learns something, epsilon is decreased in order to allow the DQN to take actions out of what it has learned.\n",
    "\n",
    "* **nb_frames**: A sequence of game frames which are used by the DQN during convolution.\n",
    "\n",
    "* **grid_size**: Specify the play area\n",
    "\n",
    "* **rewards**: The outcome of actions that the agent will recieve. In this game, there are 3 primary events that occur out of the actions taken- Eat food, Stay alive, Die. Based on the event, a reward is granted to the agent.\n",
    "\n",
    "* **load_path & save_path**: These parameters are for loading or saving the weights from training the model, so that they can be used as a base to further train the model.\n",
    "\n",
    "**How it works:**\n",
    "The agents takes the parameters and uses a _Convolutional Neural Network_ to build a DQN. It then obtains an instance of the game environment and begins training on it. The training process comprises of the following steps:\n",
    "* For half of the *nb_epochs*, take random actions and capture the game states and rewards - refered as **Experience Replay**.\n",
    "* While the first half of the training consists of random actions (exploration), the other half is all about the model taking actions, known as _exploitation_.\n",
    "* The set of experiences are sub-sampled into a batches of size *batch_size*.\n",
    "* The batches are iterated through and a set of target Q-values are calculated using the _Bellman equation_.\n",
    "* These Q-values are mapped to the states, which gives us kind of a  Q-table that is fed to the neural network for training.\n",
    "\n",
    "Once the training process is complete, we test the agent for a certain number of episodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent(object):\n",
    "    def __init__(self, \n",
    "                 all_possible_actions,\n",
    "                 gamma=0.9, \n",
    "                 batch_size=32,\n",
    "                 epsilon=1,\n",
    "                 nb_frames = 4,\n",
    "                 grid_size=10,\n",
    "                 rewards=[5, -1, -10],\n",
    "                load_path='',\n",
    "                save_path=''):\n",
    "        \n",
    "        self.gamma = gamma\n",
    "        self.batch_size = batch_size\n",
    "        self.epsilon = epsilon\n",
    "        self.min_epsilon = 0.3\n",
    "        self.epsilon_rate = 0.99\n",
    "        self.action_set = all_possible_actions\n",
    "        self.nb_actions = len(self.action_set)\n",
    "        self.rewards = rewards\n",
    "        self.nb_frames = nb_frames\n",
    "        self.save_path = save_path\n",
    "        \n",
    "        self.grid_size = grid_size\n",
    "\n",
    "        self.model = self.build_model(load_path)\n",
    "        \n",
    "        self.env = Snake(self.rewards, self.grid_size)\n",
    "        \n",
    "    def build_model(self, load_path):\n",
    "        num_filters = [16, 32]\n",
    "        \n",
    "        model = Sequential()\n",
    "        model.add(BatchNormalization(axis=1, input_shape=(self.nb_frames, self.grid_size, self.grid_size)))\n",
    "        for filters in num_filters:\n",
    "            model.add(Conv2D(filters=filters, \n",
    "                             input_shape = (self.nb_frames, self.grid_size, self.grid_size), \n",
    "                             kernel_size=(3,3), \n",
    "                             padding='same', \n",
    "                             activation='relu'))\n",
    "            model.add(MaxPooling2D(pool_size=(2, 2), strides=2, padding='same'))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(256, activation='relu'))\n",
    "        model.add(Dense(self.nb_actions, activation='softmax'))\n",
    "                       \n",
    "        if load_path!='':\n",
    "            model.load_weights(load_path)\n",
    "        model.compile(optimizer=SGD(lr=0.001), loss='mse', metrics=['accuracy'])\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def save_weights(self):\n",
    "        if self.save_path!='':\n",
    "            self.model.save_weights(self.save_path, overwrite=True)\n",
    "    \n",
    "    def model_summary(self):\n",
    "        print(self.model.summary())\n",
    "    \n",
    "    def experience_replay(self, batch_size):\n",
    "        \"\"\"\n",
    "        Coroutine of experience replay.\n",
    "\n",
    "        Provide a new experience by calling send, which in turn yields \n",
    "        a random batch of previous replay experiences.\n",
    "        \"\"\"\n",
    "        memory = []\n",
    "        while True:\n",
    "            experience = yield rsample(memory, batch_size) if batch_size <= len(memory) else None\n",
    "            memory.append(experience)\n",
    "    \n",
    "\n",
    "    def train(self, nb_epochs=1000):\n",
    "        self.exp_replay = self.experience_replay(self.batch_size)\n",
    "        # Start experience replay coroutine\n",
    "        next(self.exp_replay)\n",
    "        \n",
    "        for i in range(nb_epochs):\n",
    "            g = self.env.play()\n",
    "            screen, _, _ = next(g)\n",
    "            S = np.asarray([screen] * self.nb_frames)\n",
    "            try:\n",
    "                # Decrease epsilon over the first half of training\n",
    "                if self.epsilon > self.min_epsilon:\n",
    "                    self.epsilon -= self.epsilon_rate / (nb_epochs / 2)\n",
    "\n",
    "                while True:\n",
    "                    if np.random.random() < self.epsilon:\n",
    "                        ix = np.random.randint(self.nb_actions)\n",
    "                    else:\n",
    "                        ix = np.argmax(self.model.predict(S[np.newaxis]), axis=-1)[0]\n",
    "\n",
    "                    action = self.action_set[ix]\n",
    "                    screen, reward, _ = g.send(action)\n",
    "                    S_prime = np.zeros_like(S) \n",
    "                    S_prime[1:] = S[:-1]\n",
    "                    S_prime[0] = screen\n",
    "                    experience = (S, action, reward, S_prime)\n",
    "                    S = S_prime\n",
    "\n",
    "                    batch = self.exp_replay.send(experience)\n",
    "\n",
    "                    if batch:\n",
    "                        inputs = []\n",
    "                        targets = []\n",
    "                        for s, a, r, s_prime in batch:\n",
    "                            # The targets of unchosen actions are set to the q-values of the model,\n",
    "                            # so that the corresponding errors are 0. The targets of chosen actions\n",
    "                            # are set to either the rewards, in case a terminal state has been reached, \n",
    "                            # or future discounted q-values, in case episodes are still running.\n",
    "                            t = self.model.predict(s[np.newaxis]).flatten()\n",
    "                            ix = self.action_set.index(a)\n",
    "                            if r < 0:\n",
    "                                t[ix] = r\n",
    "                            else:\n",
    "                                t[ix] = r + self.gamma * self.model.predict(s_prime[np.newaxis]).max(axis=-1)\n",
    "                            targets.append(t)\n",
    "                            inputs.append(s)\n",
    "\n",
    "                        self.model.train_on_batch(np.array(inputs), np.array(targets))    \n",
    "\n",
    "            except StopIteration:\n",
    "               pass\n",
    "            \n",
    "            if i==0 or (i+1) % 1000 == 0:\n",
    "                print('Epoch %6i/%i, epsilon: %.3f' % (i + 1, nb_epochs, self.epsilon))\n",
    "                self.save_weights()\n",
    "        \n",
    "        print('Training complete..\\n')\n",
    "\n",
    "    def render(self, render=False, save=False):\n",
    "        if save:\n",
    "            if 'images' not in os.listdir('.'):\n",
    "                os.mkdir('images')\n",
    "        \n",
    "        frame_cnt = it.count()\n",
    "        while True:\n",
    "            screen = (yield)\n",
    "            if render:\n",
    "                clear_output(wait=True)\n",
    "                plt.imshow(screen, interpolation='none', cmap='gray')\n",
    "                display(plt.show())\n",
    "            \n",
    "            if save:\n",
    "                plt.imshow(screen, interpolation='none', cmap='gray')\n",
    "                plt.savefig('images/%04i.png' % (next(frame_cnt), ))\n",
    "    \n",
    "    \n",
    "    def test(self, render, nb_episodes=10):\n",
    "        img_saver = self.render(render)\n",
    "        next(img_saver)\n",
    "        \n",
    "        scores = []\n",
    "        self.max_episode_length = 100\n",
    "        \n",
    "        for _ in range(nb_episodes):\n",
    "            alive_reward_cap = 0\n",
    "\n",
    "            g = self.env.play()\n",
    "            screen, _, init_score = next(g)\n",
    "            img_saver.send(screen)\n",
    "            frame_cnt = it.count()\n",
    "            try:\n",
    "                S = np.asarray([screen] * self.nb_frames)\n",
    "                while True:\n",
    "                    next(frame_cnt)\n",
    "                    ix = np.argmax(self.model.predict(S[np.newaxis]), axis=-1)[0]\n",
    "                    screen, r, score = g.send(self.action_set[ix])\n",
    "                    S[1:] = S[:-1]\n",
    "                    S[0] = screen\n",
    "                    img_saver.send(screen)\n",
    "\n",
    "                    if r % 5 == 0:\n",
    "                        alive_reward_cap = 0\n",
    "                    elif r == -1:\n",
    "                        alive_reward_cap += 1\n",
    "\n",
    "                    if alive_reward_cap > self.max_episode_length * (score+1):\n",
    "                        raise StopIteration\n",
    "\n",
    "            except StopIteration:\n",
    "                scores.append(score)\n",
    "                \n",
    "        img_saver.close()\n",
    "        return scores\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's play!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have all the necessary code in place, its time to train the agent and test it after that.\n",
    "\n",
    "The way this is implemented is - For a certain number of attempts, the agent will play the game for some episodes and the scores will be collected for each of them. If the maximum score out of those episode scores is less than a minimum score (of 5), then the agent will be trained for, say 5000 epochs. This will go on until the maximum score achieved is more than 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def playSnake(training_iterations=1000, \n",
    "              test_episodes=10,\n",
    "              show_model=False):\n",
    "    \n",
    "    params = dict(\n",
    "        all_possible_actions=((0, 0), (-1, 0), (1, 0), (0, -1), (0, 1)),\n",
    "                     gamma=0.8, \n",
    "                     batch_size=64,\n",
    "                     epsilon=1,\n",
    "                     nb_frames = 2,\n",
    "                     grid_size=10,\n",
    "                     rewards=[5, -1, -10],\n",
    "                    load_path='game_weights/snake_game_weights_v2.h5',\n",
    "                    save_path=''\n",
    "    )\n",
    "\n",
    "    target_score = 8\n",
    "    max_scores = []\n",
    "    attempts = 2\n",
    "    \n",
    "    agent = Agent(**params)\n",
    "    \n",
    "    if show_model:\n",
    "        agent.model_summary()\n",
    "    \n",
    "    for attempt in range(attempts):\n",
    "        # ====Testing the model====\n",
    "        scores = agent.test(render=False, nb_episodes=test_episodes)\n",
    "        max_scores.append(max(scores))\n",
    "        \n",
    "        if max(scores) == target_score:\n",
    "            print(\"\\n==========\\nTarget achieved successfully!\\n==========\")\n",
    "            plt.bar(range(len(scores)),scores)\n",
    "            break\n",
    "        \n",
    "        if max(scores) <= 5:\n",
    "            # ====Training the model====\n",
    "            print('\\n-----Commencing Training process-----')\n",
    "            agent.train(nb_epochs=training_iterations)\n",
    "            \n",
    "    if attempts > 1:\n",
    "        plt.title('Max. Scores per iteration')\n",
    "        plt.plot(max_scores, label='Max scores per attempt')\n",
    "    else:\n",
    "        plt.title('Score summary per episode')\n",
    "        plt.bar(range(len(scores)),scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----Commencing Training process-----\n",
      "Epoch      1/5000, epsilon: 1.000\n",
      "Epoch   1000/5000, epsilon: 0.604\n",
      "Epoch   2000/5000, epsilon: 0.300\n",
      "Epoch   3000/5000, epsilon: 0.300\n",
      "Epoch   4000/5000, epsilon: 0.300\n",
      "Epoch   5000/5000, epsilon: 0.300\n",
      "Training complete..\n",
      "\n",
      "\n",
      "-----Commencing Training process-----\n",
      "Epoch      1/5000, epsilon: 0.300\n",
      "Epoch   1000/5000, epsilon: 0.300\n",
      "Epoch   2000/5000, epsilon: 0.300\n",
      "Epoch   3000/5000, epsilon: 0.300\n",
      "Epoch   4000/5000, epsilon: 0.300\n",
      "Epoch   5000/5000, epsilon: 0.300\n",
      "Training complete..\n",
      "\n",
      "\n",
      "-----Commencing Training process-----\n",
      "Epoch      1/5000, epsilon: 0.300\n",
      "Epoch   1000/5000, epsilon: 0.300\n",
      "Epoch   2000/5000, epsilon: 0.300\n",
      "Epoch   3000/5000, epsilon: 0.300\n",
      "Epoch   4000/5000, epsilon: 0.300\n",
      "Epoch   5000/5000, epsilon: 0.300\n",
      "Training complete..\n",
      "\n",
      "\n",
      "-----Commencing Training process-----\n",
      "Epoch      1/5000, epsilon: 0.300\n",
      "Epoch   1000/5000, epsilon: 0.300\n",
      "Epoch   2000/5000, epsilon: 0.300\n",
      "Epoch   3000/5000, epsilon: 0.300\n",
      "Epoch   4000/5000, epsilon: 0.300\n",
      "Epoch   5000/5000, epsilon: 0.300\n",
      "Training complete..\n",
      "\n",
      "\n",
      "-----Commencing Training process-----\n",
      "Epoch      1/5000, epsilon: 0.300\n",
      "Epoch   1000/5000, epsilon: 0.300\n",
      "Epoch   2000/5000, epsilon: 0.300\n",
      "Epoch   3000/5000, epsilon: 0.300\n",
      "Epoch   4000/5000, epsilon: 0.300\n",
      "Epoch   5000/5000, epsilon: 0.300\n",
      "Training complete..\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "playSnake(training_iterations=5000, test_episodes=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there is some progress made by the agent after training. Let's train it more!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----Commencing Training process-----\n",
      "Epoch      1/2000, epsilon: 0.999\n",
      "Epoch   1000/2000, epsilon: 0.299\n",
      "Epoch   2000/2000, epsilon: 0.299\n",
      "Training complete..\n",
      "\n",
      "\n",
      "-----Commencing Training process-----\n",
      "Epoch      1/2000, epsilon: 0.299\n",
      "Epoch   1000/2000, epsilon: 0.299\n",
      "Epoch   2000/2000, epsilon: 0.299\n",
      "Training complete..\n",
      "\n",
      "\n",
      "-----Commencing Training process-----\n",
      "Epoch      1/2000, epsilon: 0.299\n",
      "Epoch   1000/2000, epsilon: 0.299\n",
      "Epoch   2000/2000, epsilon: 0.299\n",
      "Training complete..\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "playSnake(training_iterations=2000, test_episodes=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright! A slight improvement in the highest score. Probably training it a lot would make the agent play better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAEICAYAAAB/Dx7IAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAFIVJREFUeJzt3X2UZHV95/H3hxlUQAggDcrD2CosGjURdnyKxgdwE5BEkj2YI7uKqDi7exLFXXbNuMmuEjeJ2fUxiTFnBAQF8QExyzLGoEZ0TQQyg4QFBiMCOsODDAKCrhtk8t0/7h0smqrpGqaru38979c5dfrWvb+693vvr/pTt351qztVhSSpHbssdAGSpO1jcEtSYwxuSWqMwS1JjTG4JakxBrckNcbglhqX5D8nOWOO1/mSJJvmcp2aOwb3IpfkhUn+NskPktyV5G+SPHuh69LiUVV/UFWnLHQdmj/LF7oAjZZkL+Bi4N8BnwIeBfwi8I9zvJ1lVbVlLte52CVZXlUP7Gzb1tLgGffi9s8Aqur8qtpSVT+uqkuq6uqtDZK8McmGJPcluS7Jkf38pyW5NMk9Sa5N8oqBx5yd5ENJPpfkR8BLkzw6ybuTfDfJ95L8eZLdhhWV5NAkX+nfBdyZ5JP9/OkklWT5QNtLk5zST5/cv2N4X1/XjUl+oZ+/MckdSV47o84/S/KXSX7YP/bxSd6f5O4k1yc5YqD96iTfHjgWvz6wbHDbdwHv7N/BPHOgzf5Jfpxkasg+b338n/T7fX2SoweW/0ySM5PcluSWJP8tybIR237HkPXvMlD/95N8Ksm+M47rqiS39ts4beCx70hybj/9mCTn9uu4J8nfJTmgX3Zgkov6/b4hyRsH1rFbf7zvTnId8OwZ9R2Y5DNJNie5Kcmbhz03ND8M7sXtH4AtSc5JcmySfQYXJnklXQicBOwFvAL4fpJdgf8FXALsD7wJOC/J4QMP/1fA7wN7Al8D/ojuheJZwKHAQcB/HVHXO/t17wMcDPzJduzTc4GrgccBHwc+QRcShwKvBv40yWMH2v8G8LvAfnTvNL4OXNnfvwB470Dbb9O9I/kZ4HTg3CRPmLHtG+mOye/12371wPITgS9W1eZt1H5jv+23AxduDVfgHOCBfj+OAH4JOGXIY/enO+4zvRn4NeDFwIHA3cAHZ7R5KXBYv+7VSV42ZD2vpdv/Q+iO8b8FftwvOx/Y1K//BOAPBl583g48pb/9cr8eoHtRoXs+/T3d8+Jo4C1JfnnI9jUfqsrbIr4BTwPOpvuFewC4CDigX/ZXwKlDHvOLwO3ALgPzzgfe0U+fDXx0YFmAHwFPGZj3fOCmETV9FFgDHDxj/jRQwPKBeZcCp/TTJwPfGlj2zL79AQPzvg88a6DODw8sexOwYcbj79nGsbsKOH5g29+dsfy5wMatxwlYB/zGiHWdDNwKZGDeFcBrgAPoXlR2G1h2IvDlUdsesv4NwNED958A/IRuOHPrcX3qwPL/DpzZT78DOLeffj3wt8DPzVj/IcAWYM+BeX8InN1P3wgcM7BsFbBp4DjNPHZvAz6y0L8fO+vNMe5Frqo20P3ik+SpwLnA++mC4RC6s8yZDgQ2VtU/Dcz7Dt3Z0lYbB6angN2B9Um2zguwbERZb6U7674iyd3Ae6rqrDF36XsD0z8GqKqZ8x67jfYj2yY5CfgPdEFHv2y/gfaD+0xVXd4PFb04yW10Z8sXbaP2W6pPrd536I71E4FdgdsGjt8uM7b3kG0P8UTgs0kG+2wL3YvCsHV8h+6Fa6aP0T0vPpFkb7rny+/0dd5VVffNWMfKfvrAIesfrO3AJPcMzFsG/O9Z9kkTYnA3pKquT3I28G/6WRvp3trOdCtwSJJdBsJ7Bd3Qy4OrG5i+ky4En15Vt4xRx+3AG6G76gX4YpKvAj/om+wO3NtPP3629c2FJE8EPkz3Nv7rVbUlyVV0L0APlj7koefQDZfcDlxQVf9vG5s5KEkGwnsFXdBvpDvj3q9Gf+g425/h3Ai8vqr+ZuaCJNP95CHA9QPbvvVhG6n6Cd0w0en94z4HfJNuaGvfJHsOhPcKYGt/39av/9qBZYO13VRVh82yD5onjnEvYkmemuS0JAf39w+hO9O+rG9yBvAfk/zzdA7tA+xyuqGPtybZNclLgF+lG9N9mD7cPwy8L8n+/bYOGjWGmeSVW2uiG4stYEt1Y8O3AK9OsizJ6xn+wjIJe/R1bO5rfB3wjDEe9zHg1+nC+6OztN0feHN/TF9JN4z1uaq6jS4Y35Nkr/6DxqckefF21P/nwO/3/UeSqSTHz2jzX5LsnuTpwOuAT85cSZKXJnlm/8HovXTDLVuqaiPdEMof9h9g/hzwBuC8/qGfAt6WZJ++b980sNorgHuT/Hb/IeayJM+Il6UuGIN7cbuPbnxx61v6y4BrgNMAqurTdB90fbxv+xfAvlV1P90HlcfSnU3/GXBSVV3/sC381G8DNwCXJbkX+CJw+Ii2z+5r+iHdGeepVXVTv+yNwH+iG6t+Ol1YTFxVXQe8h+7Dy+/RDSM87Ox1yOM20X3YWcz+1v9yug8H76Q77idU1ff7ZSfRXa55Hd2L2QV049Tj+gDdsbwkyX10ff3cGW2+QtdHXwLeXVWXDFnP4/tt30s3bv4VuuES6F70p+nO1D8LvL2qvtAvO51ueOQmuhehj21dYXWXiv4q3QfXN/X7fwbdh6BaAHnokJ2080lyFnBrVf3uNtqcTPch6wvnrbCfbnuaLjB33cZQjHYijnFrp9aH4r+ku4RPaoJDJdppJXkn3dDT/xgY6pEWPYdKJKkxnnFLUmMmMsa933771fT09CRWLUlL0vr16++sqof9nZxhJhLc09PTrFu3bhKrlqQlKcl3Zm/VcahEkhpjcEtSYwxuSWqMwS1JjTG4JakxBrckNWbW4E5yeJKrBm73JnnLfBQnSXq4Wa/jrqpv0v05R/q/8XsL3Z+ElCQtgO0dKjka+HZVjX2huCRpbm1vcL+K7p/OPkySVUnWJVm3efOof5KtYaZXr2V69dqFLkNSI8YO7iSPovuvKp8etryq1lTVyqpaOTU11tftJUmPwPaccR8LXDnjP3JLkubZ9gT3iYwYJpEkzZ+xgjvJ7sC/AC6cbDmSpNmM9Wddq+r/Ao+bcC2SpDH4zUlJaozBLUmNMbglqTEGtyQ1xuCWpMYY3JLUGINbkhpjcEtSYwxuSWqMwS1JjTG4JakxBrckNcbglqTGGNyS1BiDW5IaY3BLUmMMbklqjMEtSY0xuCWpMQa3JDVm3P/yvneSC5Jcn2RDkudPujBJ0nBj/Zd34APA56vqhCSPAnafYE2SpG2YNbiT7AW8CDgZoKruB+6fbFmSpFHGGSp5MrAZ+EiSbyQ5I8keMxslWZVkXZJ1mzdvnvNCdxbTq9cyvXrtQpchaREbJ7iXA0cCH6qqI4AfAatnNqqqNVW1sqpWTk1NzXGZkqStxgnuTcCmqrq8v38BXZBLkhbArMFdVbcDG5Mc3s86GrhuolVJkkYa96qSNwHn9VeU3Ai8bnIlSZK2ZazgrqqrgJUTrkWSNAa/OSlJjTG4JakxBrckNcbglqTGGNyS1BiDW5IaY3BLUmMMbklqjMEtSY0xuCWpMQa3JDXG4JakxhjcktQYg1uSGmNwS1JjDG5JaozBLUmNMbglqTEGtyQ1xuCWpMYY3JLUmLH+y3uSm4H7gC3AA1Xlf3yXpAUyVnD3XlpVd06sEknSWBwqkaTGjBvcBVySZH2SVcMaJFmVZF2SdZs3b567CiUtGtOr1zK9eu1Cl7HozPdxGTe4X1BVRwLHAr+Z5EUzG1TVmqpaWVUrp6am5rRISdJPjRXcVXVr//MO4LPAcyZZlCRptFmDO8keSfbcOg38EnDNpAuTJA03zlUlBwCfTbK1/cer6vMTrUqSNNKswV1VNwI/Pw+1SJLG4OWAktQYg1uSGmNwS1JjDG5JaozBLUmNMbglqTEGtyQ1xuCWpMYY3JLUGINbkhpjcEtSYwxuSWqMwS1JjTG4JakxBrckNcbglqTGGNyS1BiDW5IaY3BLUmMMbklqzNjBnWRZkm8kuXiSBUmStm17zrhPBTZMqhBJ0njGCu4kBwPHAWdMthxJ0myWj9nu/cBbgT1HNUiyClgFsGLFih2vTNKCmF699sHpm9913KztttVmqVks+zzrGXeSXwHuqKr122pXVWuqamVVrZyampqzAiVJDzXOUMkLgFckuRn4BHBUknMnWpUkaaRZg7uq3lZVB1fVNPAq4K+r6tUTr0ySNJTXcUtSY8b9cBKAqroUuHQilUiSxuIZtyQ1xuCWpMYY3JLUGINbkhpjcEtSYwxuSWqMwS1JjTG4JakxBrckNcbglqTGGNyS1BiDW5IaY3BLUmMMbklqjMEtSY0xuCWpMQa3JDXG4JakxhjcktQYg1uSGmNwS1JjZg3uJI9JckWSv09ybZLT56MwSdJwy8do84/AUVX1wyS7Al9L8pdVddmEa5MkDTFrcFdVAT/s7+7a32qSRUmSRhvnjJsky4D1wKHAB6vq8iFtVgGrAFasWDGXNS6o6dVrH5y++V3Hzfl6d3Sdo9YzV3UPrmfQYjwWj3S729r2pPpf7Vuo5y2M+eFkVW2pqmcBBwPPSfKMIW3WVNXKqlo5NTU113VKknrbdVVJVd0DXAocM5FqJEmzGueqkqkke/fTuwEvA66fdGGSpOHGGeN+AnBOP869C/Cpqrp4smVJkkYZ56qSq4Ej5qEWSdIY/OakJDXG4JakxhjcktQYg1uSGmNwS1JjDG5JaozBLUmNMbglqTEGtyQ1xuCWpMYY3JLUGINbkhpjcEtSYwxuSWqMwS1JjTG4JakxBrckNcbglqTGGNyS1BiDW5IaM2twJzkkyZeTbEhybZJT56MwSdJws/6Xd+AB4LSqujLJnsD6JF+oqusmXJskaYhZz7ir6raqurKfvg/YABw06cIkScNt1xh3kmngCODySRQjSZrdOEMlACR5LPAZ4C1Vde+Q5auAVQArVqx4xAVNr14LwM3vOu4h0+O0n09btzvJbW/vvg3WtJAWqt9G9cn29tV8H8dRx2JHjtE4+zzucXmkz8Nxf4e1/cY6406yK11on1dVFw5rU1VrqmplVa2cmpqayxolSQPGuaokwJnAhqp67+RLkiRtyzhn3C8AXgMcleSq/vbyCdclSRph1jHuqvoakHmoRZI0Br85KUmNMbglqTEGtyQ1xuCWpMYY3JLUGINbkhpjcEtSYwxuSWqMwS1JjTG4JakxBrckNcbglqTGGNyS1BiDW5IaY3BLUmMMbklqjMEtSY0xuCWpMQa3JDXG4JakxhjcktSYWYM7yVlJ7khyzXwUJEnatnHOuM8GjplwHZKkMc0a3FX1VeCueahFkjSG5XO1oiSrgFUAK1asmKvVPmh69VoAbn7XcQ+Znq3NsHYz22+rzaj2O1rffNre/dze9W5rndu7z4+0/XwZp593pP32rGfmuub7WMyVHenzcfZ/VJv56LdJmbMPJ6tqTVWtrKqVU1NTc7VaSdIMXlUiSY0xuCWpMeNcDng+8HXg8CSbkrxh8mVJkkaZ9cPJqjpxPgqRJI3HoRJJaozBLUmNMbglqTEGtyQ1xuCWpMYY3JLUGINbkhpjcEtSYwxuSWqMwS1JjTG4JakxBrckNcbglqTGGNyS1BiDW5IaY3BLUmMMbklqjMEtSY0xuCWpMQa3JDXG4JakxowV3EmOSfLNJDckWT3poiRJo80a3EmWAR8EjgV+Fjgxyc9OujBJ0nDjnHE/B7ihqm6sqvuBTwDHT7YsSdIoqaptN0hOAI6pqlP6+68BnltVvzWj3SpgVX/3cOCbO1DXfsCdO/D4FrnPOwf3eefwSPb5iVU1NU7D5WO0yZB5D0v7qloDrBlno7NuMFlXVSvnYl2tcJ93Du7zzmHS+zzOUMkm4JCB+wcDt06mHEnSbMYJ7r8DDkvypCSPAl4FXDTZsiRJo8w6VFJVDyT5LeCvgGXAWVV17YTrmpMhl8a4zzsH93nnMNF9nvXDSUnS4uI3JyWpMQa3JDVm0QX3Uv96fZJDknw5yYYk1yY5tZ+/b5IvJPlW/3Ofha51riVZluQbSS7u7z8pyeX9Pn+y//B7yUiyd5ILklzf9/fzl3o/J/n3/fP6miTnJ3nMUuznJGcluSPJNQPzhvZtOn/cZ9rVSY7c0e0vquDeSb5e/wBwWlU9DXge8Jv9Pq4GvlRVhwFf6u8vNacCGwbu/xHwvn6f7wbesCBVTc4HgM9X1VOBn6fb9yXbz0kOAt4MrKyqZ9BdzPAqlmY/nw0cM2PeqL49Fjisv60CPrSjG19Uwc1O8PX6qrqtqq7sp++j+2U+iG4/z+mbnQP82sJUOBlJDgaOA87o7wc4Crigb7Kk9jnJXsCLgDMBqur+qrqHJd7PdFeq7ZZkObA7cBtLsJ+r6qvAXTNmj+rb44GPVucyYO8kT9iR7S+24D4I2Dhwf1M/b0lKMg0cAVwOHFBVt0EX7sD+C1fZRLwfeCvwT/39xwH3VNUD/f2l1tdPBjYDH+mHh85IsgdLuJ+r6hbg3cB36QL7B8B6lnY/DxrVt3Oea4stuMf6ev1SkOSxwGeAt1TVvQtdzyQl+RXgjqpaPzh7SNOl1NfLgSOBD1XVEcCPWELDIsP0Y7rHA08CDgT2oBsmmGkp9fM45vy5vtiCe6f4en2SXelC+7yqurCf/b2tb5/6n3csVH0T8ALgFUluphv+OoruDHzv/i01LL2+3gRsqqrL+/sX0AX5Uu7nlwE3VdXmqvoJcCHwCyztfh40qm/nPNcWW3Av+a/X92O7ZwIbquq9A4suAl7bT78W+J/zXdukVNXbqurgqpqm69O/rqp/DXwZOKFvttT2+XZgY5LD+1lHA9exhPuZbojkeUl275/nW/d5yfbzDKP69iLgpP7qkucBP9g6pPKIVdWiugEvB/4B+DbwOwtdzwT274V0b5OuBq7qby+nG/P9EvCt/ue+C13rhPb/JcDF/fSTgSuAG4BPA49e6PrmeF+fBazr+/ovgH2Wej8DpwPXA9cAHwMevRT7GTifbhz/J3Rn1G8Y1bd0QyUf7DPt/9BddbND2/cr75LUmMU2VCJJmoXBLUmNMbglqTEGtyQ1xuCWpMYY3JLUGINbkhrz/wFjSZIfuO2hjQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "playSnake(test_episodes=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"output_WX5pMq.gif\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run this cell to view a demo\n",
    "from IPython.display import HTML\n",
    "HTML('<img src=\"output_WX5pMq.gif\">')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Truth is out there!**\n",
    "After training for about 30,000 training epochs and testing for 100 episodes, the agent could achieve a highest score of 7.\n",
    "\n",
    "I have stored the weights from the training, which can be loaded directly into the model and tested.\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance can be improved in various ways, however, as per my experience during this project there is a minimal tuning that can be done by changing the following:\n",
    "\n",
    "* Model (Training parameters)\n",
    "* Reward values\n",
    "* Training iterations\n",
    "* Randomness (epsilon)\n",
    "\n",
    "In this problem, changing the reward values and randomness gave me better results than before. Furthermore, I changed the number of frames to be sent for training, which is a model input parameter of my DQN. A lot more tweaking can be done which might improve/degrade the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Common Observations about the game:\n",
    "* In most episodes, the snake takes a fixed set of moves, getting stuck in a loop.\n",
    "* If the snake keeps growing well, it usually bumps into itself and dies.\n",
    "* The snake is very good at avoiding walls, but sometimes avoids food as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, I have applied the concept of deep reinforcement learning on the classic game - Snake. I used the approach called Q-learning, which is based on value functions that estimates the expected return of being in a given state. I extended this approach to deep Q-network and used a convolutional neural network to implement it. Using this approach, the maximum score I could achieve was 7 (seven)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Future Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project can be further extended using concepts like _Policy search_ and _Actor-Critic method_. An interesting implementation would be to incorporate *Genetic algorithm* to create a population of agents and filter out the best through various generations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "<a id='references'></a>\n",
    "* [Basic Reinforcement Learning by Vctor Mayoral Vilches](https://github.com/vmayoral/basic_reinforcement_learning/blob/master/tutorial6/examples/Snake/snake.py)\n",
    "\n",
    "* [Interactive Python Notebook for RL in Catch](https://gist.github.com/cadurosar/bd54c723c1d6335a43c8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
